{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b6314d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-17T18:06:11.855125Z",
     "iopub.status.busy": "2023-02-17T18:06:11.854188Z",
     "iopub.status.idle": "2023-02-17T18:06:43.979403Z",
     "shell.execute_reply": "2023-02-17T18:06:43.977820Z"
    },
    "papermill": {
     "duration": 32.136044,
     "end_time": "2023-02-17T18:06:43.983373",
     "exception": false,
     "start_time": "2023-02-17T18:06:11.847329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting fancyimpute\r\n",
      "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting knnimpute>=0.1.0\r\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.7/site-packages (from fancyimpute) (1.0.2)\r\n",
      "Collecting cvxpy\r\n",
      "  Downloading cvxpy-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting cvxopt\r\n",
      "  Downloading cvxopt-1.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from fancyimpute) (7.2.1)\r\n",
      "Requirement already satisfied: nose in /opt/conda/lib/python3.7/site-packages (from fancyimpute) (1.3.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.7/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.21.6)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24.2->fancyimpute) (3.1.0)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.7.3)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.0.1)\r\n",
      "Collecting osqp>=0.4.1\r\n",
      "  Downloading osqp-0.6.2.post8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.2/296.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting scs>=1.1.6\r\n",
      "  Downloading scs-3.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools<=64.0.2 in /opt/conda/lib/python3.7/site-packages (from cvxpy->fancyimpute) (59.8.0)\r\n",
      "Requirement already satisfied: ecos>=2 in /opt/conda/lib/python3.7/site-packages (from cvxpy->fancyimpute) (2.0.12)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (1.0.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (23.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (1.1.0)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (2.0.1)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (22.1.0)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->fancyimpute) (6.0.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->fancyimpute) (3.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->fancyimpute) (4.1.1)\r\n",
      "Collecting qdldl\r\n",
      "  Downloading qdldl-0.1.5.post3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: fancyimpute, knnimpute\r\n",
      "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29899 sha256=bf1491824daeceb32ba16ebb7a987f8543ffd3d7f45ca4775948f633531e339d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/04/06/a1a7d89ef4e631ce6268ea2d8cde04f7290651c1ff1025ce68\r\n",
      "  Building wheel for knnimpute (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=2899dfb3171ee21aea3ff6b5d5afbe4212f37c53d61540e69226c95290f752df\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/21/a8/a045cacd9838abd5643f6bfa852c0796a99d6b1494760494e0\r\n",
      "Successfully built fancyimpute knnimpute\r\n",
      "Installing collected packages: knnimpute, cvxopt, scs, qdldl, osqp, cvxpy, fancyimpute\r\n",
      "Successfully installed cvxopt-1.3.0 cvxpy-1.3.0 fancyimpute-0.7.0 knnimpute-0.1.0 osqp-0.6.2.post8 qdldl-0.1.5.post3 scs-3.2.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m(CVXPY) Feb 17 06:06:43 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Feb 17 06:06:43 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "!pip install fancyimpute\n",
    "from fancyimpute import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69c655e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T18:06:44.004245Z",
     "iopub.status.busy": "2023-02-17T18:06:44.001645Z",
     "iopub.status.idle": "2023-02-17T18:06:44.101003Z",
     "shell.execute_reply": "2023-02-17T18:06:44.099550Z"
    },
    "papermill": {
     "duration": 0.114372,
     "end_time": "2023-02-17T18:06:44.104152",
     "exception": false,
     "start_time": "2023-02-17T18:06:43.989780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/178 with 14 missing, elapsed time: 0.022\n",
      "Imputing row 101/178 with 0 missing, elapsed time: 0.037\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/kaggle/input/lou-comp-dataset/train.csv')\n",
    "dataset_cols=['BI DS S2','Adm BD TP S2','Adm BD DS S2','Tech Index TP S2','Tech Index DS S2','Prog web TP S2','Prog web DS S2', 'Test log TP S2', 'Test log TP S2','Test DS S2','Compilation TP S2','Compilation DS S2','IA TP S2','IA DS S2','Droit Inf DS S2','Proj federe DS S2', 'Anglais DS S2','Vision Ord TP S2', 'Vision Ord DS S2','ERP TP S2','ERP DS S2','Proba TP S1','Proba DS S1','Proba EX S1','Proba M S1','Proba C S1','TLA DS S1','TLA EX S1','TLA M S1','TLA C S1','Graphe DS S1','Graphe EX S1','Graphe M S1', 'Graphe C S1','sem1_M_module_Automates et optimisation','sem1_C_module_Automates et optimisation','Ing BD TP S1','Ing BD DS S1','Ing BD EX S1','Ing BD M S1','Ing BD Cr S1','Réseaux TP S1','Réseaux DS S1','Réseaux EX S1','Réseaux M S1','Réseaux Cr S1','sem1_M_module_Bases de données et réseaux','sem1_C_module_Bases de données et réseaux','Gestion entreprise DS S1','Gestion entreprise EX S1','Gestion entreprise M S1','Gestion entreprise Cr S1','Anglais DS S1','Anglais EX S1','Anglais M S1','Anglais Cr S1','sem1_M_module_Langue et culture','sem1_C_module_Langue et culture','UML DS S1','UML EX S1','UML M S1','UML Cr S1','Java TP S1','Java DS S1','Java EX S1','Java M S1','Java Cr S1', 'sem1_M_module_CPOO', 'sem1_C_module_CPOO','SIRS TP S1','SIRS DS S1','SIRS EX S1','SIRS M S','SIRS Cr S1','OTC TP S2','OTC DS S2','OTC EX S2','OTC M S2','OTC Cr S2', 'final_Moy S1','final_credit S1','final_Moyenne générale']\n",
    "df.columns = dataset_cols\n",
    "dataset_cols\n",
    "df[df == -1]= np.nan\n",
    "knn_imputer = KNN(k=20)\n",
    "df= knn_imputer.fit_transform(df)\n",
    "df = pd.DataFrame(df, columns= dataset_cols)\n",
    "df=df.drop(['Gestion entreprise DS S1','Gestion entreprise M S1','Anglais DS S1','Anglais EX S1','Adm BD TP S2','Tech Index TP S2','Prog web TP S2','Test log TP S2','Compilation TP S2','IA TP S2','Droit Inf DS S2','Anglais DS S2','Vision Ord TP S2','ERP TP S2','Proba TP S1','Proba C S1','TLA C S1','Graphe C S1','sem1_C_module_Automates et optimisation','Ing BD TP S1','Réseaux TP S1','Réseaux Cr S1','sem1_C_module_Bases de données et réseaux','Gestion entreprise Cr S1','Anglais Cr S1','sem1_C_module_Langue et culture','UML Cr S1','Java TP S1','Java Cr S1','sem1_C_module_CPOO','SIRS TP S1','SIRS Cr S1','OTC TP S2','OTC Cr S2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "989db5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T18:06:44.118559Z",
     "iopub.status.busy": "2023-02-17T18:06:44.118047Z",
     "iopub.status.idle": "2023-02-17T18:06:44.742620Z",
     "shell.execute_reply": "2023-02-17T18:06:44.741368Z"
    },
    "papermill": {
     "duration": 0.635363,
     "end_time": "2023-02-17T18:06:44.745862",
     "exception": false,
     "start_time": "2023-02-17T18:06:44.110499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 18:06:44.158444: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64::/opt/conda/lib\n",
      "2023-02-17 18:06:44.158527: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "train, validate = np.split(df.sample(frac = 1), [int(0.8*(len(df)))])\n",
    "X_train, y_train = train.iloc[:,:-1], train.iloc[:, -1].values.reshape(-1, 1)\n",
    "X_validate, y_validate = validate.iloc[:,:-1], validate.iloc[:, -1].values.reshape(-1,1)\n",
    "normalizer = tf.keras.layers.Normalization(input_shape=(46,), axis= None)\n",
    "normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a573ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T18:06:44.761125Z",
     "iopub.status.busy": "2023-02-17T18:06:44.760576Z",
     "iopub.status.idle": "2023-02-17T18:06:44.771639Z",
     "shell.execute_reply": "2023-02-17T18:06:44.769923Z"
    },
    "papermill": {
     "duration": 0.02178,
     "end_time": "2023-02-17T18:06:44.774512",
     "exception": false,
     "start_time": "2023-02-17T18:06:44.752732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, node_nbr_l1, node_nbr_l2, node_nbr_l3, batch_size, dropout_prob, alpha, epochs):\n",
    "    nn_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(node_nbr_l1, activation=\"relu\", input_shape=(46,)),\n",
    "          tf.keras.layers.Dropout(dropout_prob),\n",
    "          tf.keras.layers.Dense(node_nbr_l2, activation=\"relu\"),\n",
    "          tf.keras.layers.Dropout(dropout_prob),\n",
    "          tf.keras.layers.Dense(node_nbr_l3, activation=\"relu\"),\n",
    "          tf.keras.layers.Dropout(dropout_prob),\n",
    "          tf.keras.layers.Dense(1, activation =\"relu\"),])\n",
    "    nn_model.compile(optimizer = tf.keras.optimizers.Adam(alpha), loss= \"mean_absolute_error\", metrics = [\"accuracy\"])\n",
    "\n",
    "    history = nn_model.fit(\n",
    "    X_train, y_train, epochs = epochs, batch_size = batch_size, validation_split = 0.2, verbose =0\n",
    "      )\n",
    "    return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6a3ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T18:06:44.789298Z",
     "iopub.status.busy": "2023-02-17T18:06:44.788814Z",
     "iopub.status.idle": "2023-02-18T03:19:05.484227Z",
     "shell.execute_reply": "2023-02-18T03:19:05.482964Z"
    },
    "papermill": {
     "duration": 33140.845781,
     "end_time": "2023-02-18T03:19:05.626550",
     "exception": false,
     "start_time": "2023-02-17T18:06:44.780769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3670 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7139 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0000 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2116 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3320 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2685 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2829 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8694 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7558 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0719 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2311 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7431 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0275 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6045 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4926 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6867 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0060 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8566 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5700 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1919 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7259 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.6508 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8546 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.6465 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7382 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3019 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0415 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.2034 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5656 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3675 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6765 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8140 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.6769 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1577 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7391 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 4.4669 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8728 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.4959 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6483 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.1514 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1527 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8568 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0245 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.9952 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9057 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.0335 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2125 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1481 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6988 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9691 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7754 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7755 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4253 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.4486 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6905 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7691 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5856 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.3065 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4265 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1015 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9762 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9674 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2812 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3182 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7244 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0253 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6479 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.6806 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7073 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1639 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.9250 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0173 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1550 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9518 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6806 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8301 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7981 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 4.7701 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8695 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7845 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.8271 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7334 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5706 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7808 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8257 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4727 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5795 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2803 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3196 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.6111 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4038 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8840 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0580 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0236 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0151 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5547 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8600 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.5561 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5863 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3585 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7491 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8002 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4928 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4983 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6593 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7200 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2037 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7323 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4917 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8585 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7321 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.3792 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2407 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6819 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8791 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5679 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7938 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3299 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2521 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2537 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3528 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7971 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3002 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7684 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7283 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 14ms/step - loss: 2.0254 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7279 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6039 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5530 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8457 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8088 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7081 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2876 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8027 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8372 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.6423 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0782 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6672 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5017 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8429 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9438 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4694 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0235 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 8 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.4274 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5034 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 3.5443 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8230 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7080 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2719 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3670 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1491 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.7046 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1846 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.7964 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0164 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9013 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5612 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3280 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5447 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7021 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7658 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.2842 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8115 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1286 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6822 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2838 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.5240 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3613 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1803 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3350 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0243 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.7032 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8154 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7864 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1571 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3501 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.8405 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7073 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4927 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5180 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2435 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5279 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9332 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.1617 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7771 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3797 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.3956 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3480 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0364 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6687 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7993 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6820 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6843 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5276 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.8567 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6601 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8133 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4947 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.5950 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9507 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6232 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1550 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6537 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7264 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7755 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7098 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3359 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1893 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9052 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9162 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3848 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9584 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7373 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7760 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8684 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5112 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7433 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0217 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2221 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9141 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5671 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8833 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.3782 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8456 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3845 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.3380 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7436 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7438 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7299 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5305 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0534 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6526 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1457 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.7207 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7147 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.7833 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.7640 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5738 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.6619 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3352 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1347 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7432 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2400 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5771 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1544 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4484 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3992 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5566 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4121 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0536 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7583 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3362 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1420 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2428 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8232 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4703 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4279 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4128 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2891 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7818 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8700 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5215 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9000 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 2.6462 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3419 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6997 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7770 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2177 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0083 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8313 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3568 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5067 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7199 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7839 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2210 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5255 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6782 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1779 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.1374 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.8153 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0946 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5558 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.8926 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9595 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 16 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.6570 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3590 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7609 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4554 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1653 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0438 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5955 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1909 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1869 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1992 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1336 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 10ms/step - loss: 3.7845 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7454 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6997 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4585 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6423 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9020 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2719 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6185 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2037 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2066 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5655 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7841 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.6243 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7680 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5292 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7377 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7564 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.5247 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2035 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2246 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0102 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7988 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8054 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.8206 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2551 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.8110 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.1254 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4445 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7681 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1472 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4307 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0378 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3081 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.9396 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4457 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8554 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3534 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.4864 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8083 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7068 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.6311 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7824 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4504 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8441 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 4.3631 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7039 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9528 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6324 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5968 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3273 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8650 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9841 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0781 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8937 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.7195 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4986 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7948 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6474 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4986 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4561 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.3453 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8830 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4601 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7241 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6246 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9012 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7353 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7199 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.3556 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8540 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7519 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8500 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5590 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3699 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0754 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0920 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0871 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4622 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.7275 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7933 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6183 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7361 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7328 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9917 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9796 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2430 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7744 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6005 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2604 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1157 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5105 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7710 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3549 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4003 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6662 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1299 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2210 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3326 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.5523 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6050 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6235 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3278 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7568 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2920 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.4137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9497 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9145 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7326 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2013 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2282 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6491 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2261 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5505 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.5373 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8901 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5252 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5382 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8046 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8900 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0205 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.3044 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7994 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1264 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.5066 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5622 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4457 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5973 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5892 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0331 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7952 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8110 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8348 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.0396 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1210 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5902 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 32 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.2631 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.5380 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6540 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3114 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.5692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5712 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.6507 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3604 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4657 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9380 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0442 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7606 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1923 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4294 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0102 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2703 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.2728 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3743 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7995 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6158 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0782 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4454 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7109 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3448 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2469 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6166 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.8126 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.9656 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8206 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0640 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5286 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4557 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.9303 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7257 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4357 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0315 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6042 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2289 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0797 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7059 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5650 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2376 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0587 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0424 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 4 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.2510 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7451 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7507 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9796 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.1308 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1995 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8752 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3591 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.6213 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7778 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5092 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6637 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4421 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8971 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6285 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8488 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2171 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2454 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7355 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.2890 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5949 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8281 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3157 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.1402 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8168 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6893 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4926 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.8140 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2125 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9504 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1615 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3167 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.4533 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0736 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8769 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9460 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.4228 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8354 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0451 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1893 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.2983 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3673 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6929 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.7191 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7369 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.6200 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 3.4425 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4960 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 8 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5156 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6385 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7747 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.3115 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6353 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.3833 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8566 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7868 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.3863 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1666 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6899 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3591 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 16 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2190 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6838 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.2458 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5569 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6516 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8336 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8392 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3511 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7348 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0726 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8796 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2143 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 32 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9142 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7450 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.001 dropout prob = 0.2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 03:00:19.032975: W tensorflow/core/data/root_dataset.cc:247] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2724 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5509 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3226 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8857 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7022 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7374 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.4245 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3137 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8216 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7024 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 64 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.9028 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8198 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0828 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1133 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2387 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.3692 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2828 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.01 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9248 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8430 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9469 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0005 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0248 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0 \n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6227 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.1 \n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.9420 - accuracy: 0.0000e+00\n",
      " node_nbr_l1= 32 node_nbr_l2= 64 node_nbr_l3= 16 batch size= 128 learning rate = 0.0001 dropout prob = 0.2 \n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.5551 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "minimal_loss_value = float('inf')\n",
    "efficient_model = None\n",
    "node_nbr_l1 =32# [16,32,64,128]:\n",
    "for node_nbr_l2 in [8,16,32,64]:\n",
    "    for node_nbr_l3 in [4,8,16]:\n",
    "        for batch_size in [16, 32, 64, 128]:\n",
    "            for alpha in [0.001, 0.005, 0.01, 0.0005, 0.0001]:\n",
    "                for dropout_prob in [0, 0.1, 0.2]:\n",
    "                    print(f\" node_nbr_l1= 32 node_nbr_l2= {node_nbr_l2} node_nbr_l3= {node_nbr_l3} batch size= {batch_size} learning rate = {alpha} dropout prob = {dropout_prob} \")\n",
    "                    model, history = train_model(X_train, y_train, node_nbr_l1, node_nbr_l2, node_nbr_l3, batch_size, dropout_prob, alpha, epochs)\n",
    "                    #plot_history(history)\n",
    "                    loss_value = model.evaluate(X_validate, y_validate)[0]\n",
    "                    if loss_value < minimal_loss_value:\n",
    "                        minimal_loss_value = loss_value\n",
    "                        efficient_model = model\n",
    "                        #plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f5766e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T03:19:05.913492Z",
     "iopub.status.busy": "2023-02-18T03:19:05.913018Z",
     "iopub.status.idle": "2023-02-18T03:19:06.130635Z",
     "shell.execute_reply": "2023-02-18T03:19:06.129251Z"
    },
    "papermill": {
     "duration": 0.363869,
     "end_time": "2023-02-18T03:19:06.133235",
     "exception": false,
     "start_time": "2023-02-18T03:19:05.769366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5251959835158453"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = efficient_model.predict(X_validate)\n",
    "loss=np.mean(abs((y_validate-y_pred)))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05cd3cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T03:19:06.425455Z",
     "iopub.status.busy": "2023-02-18T03:19:06.424925Z",
     "iopub.status.idle": "2023-02-18T03:19:06.577355Z",
     "shell.execute_reply": "2023-02-18T03:19:06.576190Z"
    },
    "papermill": {
     "duration": 0.301988,
     "end_time": "2023-02-18T03:19:06.580282",
     "exception": false,
     "start_time": "2023-02-18T03:19:06.278294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_cols=['BI DS S2','Adm BD TP S2','Adm BD DS S2','Tech Index TP S2','Tech Index DS S2','Prog web TP S2','Prog web DS S2', 'Test log TP S2', 'Test log TP S2','Test DS S2','Compilation TP S2','Compilation DS S2','IA TP S2','IA DS S2','Droit Inf DS S2','Proj federe DS S2', 'Anglais DS S2','Vision Ord TP S2', 'Vision Ord DS S2','ERP TP S2','ERP DS S2','Proba TP S1','Proba DS S1','Proba EX S1','Proba M S1','Proba C S1','TLA DS S1','TLA EX S1','TLA M S1','TLA C S1','Graphe DS S1','Graphe EX S1','Graphe M S1', 'Graphe C S1','sem1_M_module_Automates et optimisation','sem1_C_module_Automates et optimisation','Ing BD TP S1','Ing BD DS S1','Ing BD EX S1','Ing BD M S1','Ing BD Cr S1','Réseaux TP S1','Réseaux DS S1','Réseaux EX S1','Réseaux M S1','Réseaux Cr S1','sem1_M_module_Bases de données et réseaux','sem1_C_module_Bases de données et réseaux','Gestion entreprise DS S1','Gestion entreprise EX S1','Gestion entreprise M S1','Gestion entreprise Cr S1','Anglais DS S1','Anglais EX S1','Anglais M S1','Anglais Cr S1','sem1_M_module_Langue et culture','sem1_C_module_Langue et culture','UML DS S1','UML EX S1','UML M S1','UML Cr S1','Java TP S1','Java DS S1','Java EX S1','Java M S1','Java Cr S1', 'sem1_M_module_CPOO', 'sem1_C_module_CPOO','SIRS TP S1','SIRS DS S1','SIRS EX S1','SIRS M S','SIRS Cr S1','OTC TP S2','OTC DS S2','OTC EX S2','OTC M S2','OTC Cr S2', 'final_Moy S1','final_credit S1']\n",
    "test_data = pd.read_csv('/kaggle/input/lou-comp-dataset/test.csv')\n",
    "test_data.columns = test_cols\n",
    "test_data=test_data.drop(['Gestion entreprise DS S1','Gestion entreprise M S1','Anglais DS S1','Anglais EX S1','Adm BD TP S2','Tech Index TP S2','Prog web TP S2','Test log TP S2','Compilation TP S2','IA TP S2','Droit Inf DS S2','Anglais DS S2','Vision Ord TP S2','ERP TP S2','Proba TP S1','Proba C S1','TLA C S1','Graphe C S1','sem1_C_module_Automates et optimisation','Ing BD TP S1','Réseaux TP S1','Réseaux Cr S1','sem1_C_module_Bases de données et réseaux','Gestion entreprise Cr S1','Anglais Cr S1','sem1_C_module_Langue et culture','UML Cr S1','Java TP S1','Java Cr S1','sem1_C_module_CPOO','SIRS TP S1','SIRS Cr S1','OTC TP S2','OTC Cr S2'], axis=1)\n",
    "preds = efficient_model.predict(test_data)\n",
    "sub = pd.read_csv('/kaggle/input/lou-comp-dataset/Sample Submission.csv')\n",
    "sub[\"final_Moyenne générale\"] = preds\n",
    "sub.to_csv(\"submission.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33188.011636,
   "end_time": "2023-02-18T03:19:10.406800",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-17T18:06:02.395164",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
